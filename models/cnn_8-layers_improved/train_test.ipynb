{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citlalli/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "from skimage import io, color, exposure, transform\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Define functions -------------------------------\n",
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "    \n",
    "    # Re-scale image\n",
    "    img = transform.resize(img, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from X_train_german.h5\n"
     ]
    }
   ],
   "source": [
    "#------- Read training images---------------------------------------------------\n",
    "NUM_CLASSES = 43 # 43 for GTSRB, 164 for European data set\n",
    "IMAGE_DIMS = (48,48,3)\n",
    "file_name = 'X_train_german.h5' # File name for saving your training images\n",
    "\n",
    "try:\n",
    "    with  h5py.File(file_name) as hf: \n",
    "        X, Y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from {}\".format(file_name))\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading {}. Processing all images...\".format(file_name))\n",
    "    root_dir = '../../Datasets/Traffic_signs/GTSRB/Final_Training/Images' # changed to your needs\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    # Read all image paths with extension ppm\n",
    "    all_img_paths = sorted(glob.glob(os.path.join(root_dir, '*/*.ppm')) )\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    \n",
    "    # Read images and preprocess them\n",
    "    print(\"[INFO] loading images...\")\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))            \n",
    "            label = get_class(img_path)            \n",
    "            \n",
    "            # Save images and labels in lists\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "    # Save the training dictionary\n",
    "    with h5py.File(file_name,'w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded images from X_test_german.h5\n"
     ]
    }
   ],
   "source": [
    "#--------------- Read test images-------------------------------\n",
    "file_name = 'X_test_german.h5' # File name for saving your testing images\n",
    "\n",
    "try:\n",
    "    with  h5py.File(file_name) as hf: \n",
    "        X_test, y_test = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from {}\".format(file_name))\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading {}. Processing all images...\".format(file_name))\n",
    "    root_dir = '../../Datasets/Traffic_signs/GTSRB/Final_Test/Images2'\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    # Read all image paths with extension ppm\n",
    "    all_img_paths = sorted(glob.glob(os.path.join(root_dir, '*/*.ppm')) )\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(all_img_paths)\n",
    "\n",
    "    # Read images and preprocess them    \n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))            \n",
    "            label = get_class(img_path)\n",
    "            \n",
    "            # Save images and labels in lists\n",
    "            X_test.append(img)\n",
    "            y_test.append(label)\n",
    "\n",
    "            if len(X_test)%1000 == 0: print(\"Processed {}/{}\".format(len(X_test), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X_test = np.array(X_test, dtype='float32')\n",
    "    y_test = np.array(y_test, dtype='uint8')\n",
    "    # Save testing dictionary\n",
    "    with h5py.File(file_name,'w') as hf:\n",
    "        hf.create_dataset('imgs', data=X_test)\n",
    "        hf.create_dataset('labels', data=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Split dataset into train and validation -----------------------------\n",
    "# partition the data into training and validation sets using 90% - 10% ratio\n",
    "split = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "(X_train, X_val, y_train, y_val) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (35288, 48, 48, 3)\n",
      "Train classes labels shape:  (35288, 43)\n",
      "Validation data shape:  (3921, 48, 48, 3)\n",
      "Validation classes labels shape:  (3921, 43)\n",
      "Test data shape:  (12630, 48, 48, 3)\n",
      "Test classes labels shape:  (12630,)\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Normalize the data ----------------------------------\n",
    "normalize = 0\n",
    "# Subtract the mean image\n",
    "if normalize:#\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_val -= mean_image\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train classes labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation classes labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test classes labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 8-layers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Initialization of weights -------------------------------\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "def my_init(shape, name=None):\n",
    "    value = np.random.random(shape)\n",
    "    return K.variable(value, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                11051     \n",
      "_________________________________________________________________\n",
      "class_output (Activation)    (None, 43)                0         \n",
      "=================================================================\n",
      "Total params: 1,480,779\n",
      "Trainable params: 1,479,371\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --------------- Define Keras model ---------------------------------- \n",
    "from model.TS_Net_proposal import TrafficSignsNet\n",
    "\n",
    "model = TrafficSignsNet.build(48, 48,\n",
    "    numClasses=43,\n",
    "    finalAct=\"softmax\")\n",
    "\n",
    "model.summary() # Print model information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- Initialize model ------------------------\n",
    "EPOCHS = 40\n",
    "INIT_LR = 1e-3\n",
    "BS = 128\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** init(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citlalli/.local/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 35288 samples, validate on 3921 samples\n",
      "Epoch 1/40\n",
      "35288/35288 [==============================] - 27s 759us/step - loss: 0.9790 - acc: 0.7869 - val_loss: 0.2982 - val_acc: 0.9617\n",
      "Epoch 2/40\n",
      "35288/35288 [==============================] - 24s 672us/step - loss: 0.2669 - acc: 0.9772 - val_loss: 0.2066 - val_acc: 0.9913\n",
      "Epoch 3/40\n",
      "35288/35288 [==============================] - 24s 675us/step - loss: 0.2127 - acc: 0.9889 - val_loss: 0.1824 - val_acc: 0.9946\n",
      "Epoch 4/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1932 - acc: 0.9922 - val_loss: 0.1691 - val_acc: 0.9967\n",
      "Epoch 5/40\n",
      "35288/35288 [==============================] - 24s 675us/step - loss: 0.1803 - acc: 0.9938 - val_loss: 0.1757 - val_acc: 0.9939\n",
      "Epoch 6/40\n",
      "35288/35288 [==============================] - 24s 674us/step - loss: 0.1766 - acc: 0.9933 - val_loss: 0.1697 - val_acc: 0.9941\n",
      "Epoch 7/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1714 - acc: 0.9940 - val_loss: 0.1614 - val_acc: 0.9974\n",
      "Epoch 8/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1652 - acc: 0.9952 - val_loss: 0.1659 - val_acc: 0.9934\n",
      "Epoch 9/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1664 - acc: 0.9941 - val_loss: 0.1683 - val_acc: 0.9944\n",
      "Epoch 10/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1605 - acc: 0.9960 - val_loss: 0.1654 - val_acc: 0.9929\n",
      "Epoch 11/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1610 - acc: 0.9944 - val_loss: 0.1776 - val_acc: 0.9913\n",
      "Epoch 12/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1785 - acc: 0.9936 - val_loss: 0.1778 - val_acc: 0.9941\n",
      "Epoch 13/40\n",
      "35288/35288 [==============================] - 24s 676us/step - loss: 0.1639 - acc: 0.9967 - val_loss: 0.1492 - val_acc: 0.9977\n",
      "Epoch 14/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1584 - acc: 0.9953 - val_loss: 0.1765 - val_acc: 0.9926\n",
      "Epoch 15/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1733 - acc: 0.9943 - val_loss: 0.1723 - val_acc: 0.9962\n",
      "Epoch 16/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1732 - acc: 0.9955 - val_loss: 0.1776 - val_acc: 0.9952\n",
      "Epoch 17/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1697 - acc: 0.9958 - val_loss: 0.1678 - val_acc: 0.9941\n",
      "Epoch 18/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1750 - acc: 0.9944 - val_loss: 0.1986 - val_acc: 0.9875\n",
      "Epoch 19/40\n",
      "35288/35288 [==============================] - 23s 657us/step - loss: 0.1755 - acc: 0.9951 - val_loss: 0.1738 - val_acc: 0.9957\n",
      "Epoch 20/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1668 - acc: 0.9956 - val_loss: 0.1604 - val_acc: 0.9972\n",
      "Epoch 21/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1629 - acc: 0.9963 - val_loss: 0.1565 - val_acc: 0.9967\n",
      "Epoch 22/40\n",
      "35288/35288 [==============================] - 23s 656us/step - loss: 0.1744 - acc: 0.9942 - val_loss: 0.1758 - val_acc: 0.9964\n",
      "Epoch 23/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1685 - acc: 0.9961 - val_loss: 0.1872 - val_acc: 0.9878\n",
      "Epoch 24/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1640 - acc: 0.9959 - val_loss: 0.1485 - val_acc: 0.9995\n",
      "Epoch 25/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1564 - acc: 0.9964 - val_loss: 0.1481 - val_acc: 0.9980\n",
      "Epoch 26/40\n",
      "35288/35288 [==============================] - 23s 657us/step - loss: 0.1531 - acc: 0.9956 - val_loss: 0.1615 - val_acc: 0.9952\n",
      "Epoch 27/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1628 - acc: 0.9955 - val_loss: 0.1628 - val_acc: 0.9952\n",
      "Epoch 28/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1520 - acc: 0.9969 - val_loss: 0.1463 - val_acc: 0.9964\n",
      "Epoch 29/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1492 - acc: 0.9969 - val_loss: 0.1411 - val_acc: 0.9977\n",
      "Epoch 30/40\n",
      "35288/35288 [==============================] - 23s 659us/step - loss: 0.1452 - acc: 0.9962 - val_loss: 0.1463 - val_acc: 0.9980\n",
      "Epoch 31/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1558 - acc: 0.9947 - val_loss: 0.1653 - val_acc: 0.9957\n",
      "Epoch 32/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1577 - acc: 0.9963 - val_loss: 0.1505 - val_acc: 0.9964\n",
      "Epoch 33/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1437 - acc: 0.9971 - val_loss: 0.1404 - val_acc: 0.9952\n",
      "Epoch 34/40\n",
      "35288/35288 [==============================] - 23s 656us/step - loss: 0.1361 - acc: 0.9971 - val_loss: 0.1326 - val_acc: 0.9969\n",
      "Epoch 35/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1482 - acc: 0.9953 - val_loss: 0.1455 - val_acc: 0.9962\n",
      "Epoch 36/40\n",
      "35288/35288 [==============================] - 23s 656us/step - loss: 0.1389 - acc: 0.9971 - val_loss: 0.3116 - val_acc: 0.9663\n",
      "Epoch 37/40\n",
      "35288/35288 [==============================] - 23s 657us/step - loss: 0.1363 - acc: 0.9969 - val_loss: 0.1286 - val_acc: 0.9985\n",
      "Epoch 38/40\n",
      "35288/35288 [==============================] - 23s 658us/step - loss: 0.1349 - acc: 0.9967 - val_loss: 0.1487 - val_acc: 0.9946\n",
      "Epoch 39/40\n",
      "35288/35288 [==============================] - 23s 656us/step - loss: 0.1245 - acc: 0.9979 - val_loss: 0.1338 - val_acc: 0.9944\n",
      "Epoch 40/40\n",
      "35288/35288 [==============================] - 23s 656us/step - loss: 0.1280 - acc: 0.9968 - val_loss: 0.1384 - val_acc: 0.9964\n",
      "Time taken to train the model 941.1104226112366\n"
     ]
    }
   ],
   "source": [
    "#---------------------- Train model -----------------------\n",
    "t1=time()\n",
    "history = model.fit(X_train, y_train, batch_size=BS, \n",
    "                            nb_epoch=EPOCHS,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            shuffle = True\n",
    "         )\n",
    "t2 = time()\n",
    "\n",
    "print ('Time taken to train the model', t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.7618215084075928 sec to predict 12630 images\n",
      "Test accuracy = 98.5193982581156\n"
     ]
    }
   ],
   "source": [
    "t1=time()\n",
    "y_proba = model.predict(X_test)\n",
    "t2=time()\n",
    "print  ('Took {} sec to predict {} images'.format(t2-t1, len(X_test)) )\n",
    "\n",
    "pred_labels = []\n",
    "pred_probas = []\n",
    "for i in range(0,len(y_proba)):\n",
    "    classId = y_proba[i].argmax()\n",
    "    pred_labels.append(classId)\n",
    "    proba = max(y_proba[i])\n",
    "    pred_probas.append(proba)\n",
    "\n",
    "pred_labels = np.array(pred_labels, dtype='uint8')\n",
    "pred_probas = np.array(pred_probas)\n",
    "\n",
    "acc = np.mean(pred_labels==y_test)\n",
    "print(\"Test accuracy = {}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GTSRB_weights/german_model_98.52.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/275 [..............................] - ETA: 26s - loss: 0.5981 - acc: 0.8789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citlalli/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/home/citlalli/.local/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=275)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 18s 65ms/step - loss: 0.2722 - acc: 0.9717 - val_loss: 0.1871 - val_acc: 0.9969\n",
      "Epoch 2/50\n",
      "275/275 [==============================] - 18s 66ms/step - loss: 0.2130 - acc: 0.9893 - val_loss: 0.1818 - val_acc: 0.9964\n",
      "Epoch 3/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1958 - acc: 0.9914 - val_loss: 0.1703 - val_acc: 0.9977\n",
      "Epoch 4/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1873 - acc: 0.9918 - val_loss: 0.1669 - val_acc: 0.9969\n",
      "Epoch 5/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1789 - acc: 0.9926 - val_loss: 0.1561 - val_acc: 0.9980\n",
      "Epoch 6/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1725 - acc: 0.9928 - val_loss: 0.1511 - val_acc: 0.9987\n",
      "Epoch 7/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1680 - acc: 0.9934 - val_loss: 0.1487 - val_acc: 0.9980\n",
      "Epoch 8/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1627 - acc: 0.9939 - val_loss: 0.1430 - val_acc: 0.9987\n",
      "Epoch 9/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1605 - acc: 0.9935 - val_loss: 0.1462 - val_acc: 0.9974\n",
      "Epoch 10/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1575 - acc: 0.9940 - val_loss: 0.1366 - val_acc: 0.9992\n",
      "Epoch 11/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1538 - acc: 0.9942 - val_loss: 0.1376 - val_acc: 0.9977\n",
      "Epoch 12/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1502 - acc: 0.9946 - val_loss: 0.1358 - val_acc: 0.9980\n",
      "Epoch 13/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1512 - acc: 0.9940 - val_loss: 0.1359 - val_acc: 0.9974\n",
      "Epoch 14/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1468 - acc: 0.9943 - val_loss: 0.1315 - val_acc: 0.9990\n",
      "Epoch 15/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1537 - acc: 0.9935 - val_loss: 0.1345 - val_acc: 0.9985\n",
      "Epoch 16/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1455 - acc: 0.9954 - val_loss: 0.1307 - val_acc: 0.9990\n",
      "Epoch 17/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1456 - acc: 0.9949 - val_loss: 0.1303 - val_acc: 0.9985\n",
      "Epoch 18/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1420 - acc: 0.9951 - val_loss: 0.1286 - val_acc: 0.9987\n",
      "Epoch 19/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1380 - acc: 0.9955 - val_loss: 0.1255 - val_acc: 0.9982\n",
      "Epoch 20/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1379 - acc: 0.9948 - val_loss: 0.1222 - val_acc: 0.9980\n",
      "Epoch 21/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1414 - acc: 0.9945 - val_loss: 0.1248 - val_acc: 0.9990\n",
      "Epoch 22/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1348 - acc: 0.9958 - val_loss: 0.1560 - val_acc: 0.9901\n",
      "Epoch 23/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1369 - acc: 0.9950 - val_loss: 0.1305 - val_acc: 0.9959\n",
      "Epoch 24/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1361 - acc: 0.9952 - val_loss: 0.1203 - val_acc: 0.9990\n",
      "Epoch 25/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1328 - acc: 0.9954 - val_loss: 0.1206 - val_acc: 0.9985\n",
      "Epoch 26/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1330 - acc: 0.9953 - val_loss: 0.1301 - val_acc: 0.9957\n",
      "Epoch 27/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1297 - acc: 0.9959 - val_loss: 0.1385 - val_acc: 0.9921\n",
      "Epoch 28/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1302 - acc: 0.9956 - val_loss: 0.1181 - val_acc: 0.9974\n",
      "Epoch 29/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1200 - acc: 0.9972 - val_loss: 0.1382 - val_acc: 0.9906\n",
      "Epoch 30/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1291 - acc: 0.9948 - val_loss: 0.1115 - val_acc: 0.9995\n",
      "Epoch 31/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1274 - acc: 0.9952 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.1265 - acc: 0.9951 - val_loss: 0.1140 - val_acc: 0.9992\n",
      "Epoch 33/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1366 - acc: 0.9939 - val_loss: 0.1243 - val_acc: 0.9969\n",
      "Epoch 34/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1247 - acc: 0.9964 - val_loss: 0.1177 - val_acc: 0.9980\n",
      "Epoch 35/50\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.1279 - acc: 0.9952 - val_loss: 0.1150 - val_acc: 0.9982\n",
      "Epoch 36/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1217 - acc: 0.9966 - val_loss: 0.1198 - val_acc: 0.9964\n",
      "Epoch 37/50\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.1205 - acc: 0.9958 - val_loss: 0.1141 - val_acc: 0.9980\n",
      "Epoch 38/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1181 - acc: 0.9965 - val_loss: 0.1106 - val_acc: 0.9977\n",
      "Epoch 39/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1184 - acc: 0.9961 - val_loss: 0.1145 - val_acc: 0.9962\n",
      "Epoch 40/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1182 - acc: 0.9958 - val_loss: 0.1123 - val_acc: 0.9972\n",
      "Epoch 41/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1256 - acc: 0.9949 - val_loss: 0.1110 - val_acc: 0.9982\n",
      "Epoch 42/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1155 - acc: 0.9969 - val_loss: 0.1399 - val_acc: 0.9923\n",
      "Epoch 43/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1107 - acc: 0.9972 - val_loss: 0.1032 - val_acc: 0.9987\n",
      "Epoch 44/50\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.1172 - acc: 0.9953 - val_loss: 0.1047 - val_acc: 0.9990\n",
      "Epoch 45/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1106 - acc: 0.9972 - val_loss: 0.1023 - val_acc: 0.9985\n",
      "Epoch 46/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1144 - acc: 0.9955 - val_loss: 0.1036 - val_acc: 0.9990\n",
      "Epoch 47/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1081 - acc: 0.9972 - val_loss: 0.1034 - val_acc: 0.9982\n",
      "Epoch 48/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1136 - acc: 0.9956 - val_loss: 0.1136 - val_acc: 0.9962\n",
      "Epoch 49/50\n",
      "275/275 [==============================] - 19s 67ms/step - loss: 0.1150 - acc: 0.9961 - val_loss: 0.1010 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "275/275 [==============================] - 18s 67ms/step - loss: 0.1069 - acc: 0.9978 - val_loss: 0.0961 - val_acc: 0.9995\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50\n",
    "history2=model.fit_generator(datagen.flow(X_train, y_train, batch_size=BS),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            callbacks=[ReduceLROnPlateau('val_loss', factor=0.2, patience=20, verbose=1, mode='auto'), \n",
    "                                       ModelCheckpoint('GTSRB_weights/german_aug_test.h5',save_best_only=True)]\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 2.2971127033233643 sec to predict 12630 images\n",
      "Test accuracy = 99.36658749010293\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "t1=time()\n",
    "y_proba = model.predict(X_test)\n",
    "t2=time()\n",
    "print  ('Took {} sec to predict {} images'.format(t2-t1, len(X_test)) )\n",
    "\n",
    "pred_labels = []\n",
    "pred_probas = []\n",
    "for i in range(0,len(y_proba)):\n",
    "    classId = y_proba[i].argmax()\n",
    "    pred_labels.append(classId)\n",
    "    proba = max(y_proba[i])\n",
    "    pred_probas.append(proba)\n",
    "\n",
    "pred_labels = np.array(pred_labels, dtype='uint8')\n",
    "pred_probas = np.array(pred_probas)\n",
    "\n",
    "acc = np.mean(pred_labels==y_test)\n",
    "print(\"Test accuracy = {}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GTSRB/german_aug-99.37.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
